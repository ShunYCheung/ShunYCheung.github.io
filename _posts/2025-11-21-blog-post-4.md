---
title: 'Is normalising flows the future?'
date: 2025-11-22
permalink: /posts/2025/11/normalising_flows/
tags:
  - Normalising flows
  - Code
---


In the field of Gravitational-Wave astronomy, I see a transition from traditional stochastic sampling methods such as Monte Carlo Markov Chains and nested sampling towards something called *normalising flows*. As our inference problems become harder due to the increasing volume of data, we need faster inference methods. In this blog post, we will go through what is a normalising flow and can it solve inference problem that are intractably long for traditional methods. 

# Theoretical background

A normalising flows works by transforming a simple probabilty distribution (usually a Gaussian distribution) into a more complex distribution through a sequence of mappings. Let $$X$$ be a random variable with a tractable probability density function $$p_X$$. We want to transform this distribution $$p_X$$ (source distribution) into distribution $$p_Y$$ (target distribution) using an invertible (bijective) function $$g$$ where

$$\begin{align}
Y = g(X).
\end{align}$$

We can also transform $$p_Y$$ back into $$p_X$$ using the inverse function $$g^{-1}$$. 


## Change of variables

If we want to figure out the probability value close to a particular Y value, we look at the area under a small interval $$dx$$. We can do something similar for X. 

$$\begin{align}
p_Y(y)|\partial y| = p_X(x)|\partial x|
\end{align}$$

$$\begin{align}
p_Y(y) = p_X(x)|\frac{\partial x}{\partial y}|
\end{align}$$

$$\begin{align}
p_Y(y) = p_X(x)|\frac{\partial y}{\partial x}|^{-1}
\end{align}$$

substituting $$x$$ with the inverse function $$g^{-1}(y)=x$$, we have the formula

$$\begin{equation}
p_Y(y) = p_X(g^{-1}(y))\left|\frac{\partial g(g^{-1}(y))}{\partial x}\right|.
\end{equation}$$

where the term $$\vert \frac{\partial g(g^{-1}(y))}{\partial x}\vert$$ is the Jacobian. One job for the Jacobian is to ensure the new probability density *normalises* to 1. The new probability density function $$p_Y(y)$$ is called a *pushforward* of the density $$p_X$$.

The function $$g$$ (the generator) pushes forward the original density $$p_X$$ to a more complex density. This movement where the simple density *flows* to a more complex density it called the *generative direction*. We can take the inverse function $$g^{-1}$$ and use it to move in the opposite direction, turning from a complex distribution into a more simple distribution. Hence, this is why it is named *normalising flows*, we applying invertible transformations to transform probability distributions while ensuring they are normalised.


## Generative model likelihood

An obvious use for normalising flows is to perform parameter estimation. We assume that there is a only a single flow parameterised by $$\theta$$ and the original distribution is parameterised by $$\phi$$. We need to derive a likelihood function to evaluate the data with given parameters $$\psi = (\theta. \phi)$$. We can simply take the previous equation and take the logarithm on both sides, which results in our log likelihood function

$$\begin{align}
\log p_Y(y|\psi) = \log p_X(g^{-1}(y|\theta)|\phi) + \log\left|\det \frac{\partial g(g^{-1}(y|\theta))}{\partial x} \right|
\end{align}$$

where the first term is the log likelihood under the original distribution and the second term accounts for the change of volume induced by the transformation of the normalising flows. 

# Implementing normalising flows

Normalising flows should satisfy the following conditions in order to be practical:
- be invertible.
- be sufficiently expressive to model the distribution of interest.
- be computationally efficient, at computing $$g$$, $$g^{-1}$$ and also the determinant of the Jacobian. 

Constructing a complicated bijective function can be difficult. One approach is to use a simpler bijective function to compose a much more complicated function. A composite function $$g$$ made of $$N$$ invertible function $$\{g_i\}_{i=0}^{N}$$ is itself invertible and the determinant of its Jacobian has a specific form. Hence, $$g$$ is bijective and the inverse

$$\begin{align}
g^{-1} = g^{-1}_0 \circ g^{-1}_1 \circ ... \circ g^{-1}_N
\end{align}$$

and the determinant of the Jacobian is 

$$\begin{align}
\det\left( \frac{\partial g(g^{-1}(y|\theta))}{\partial x}\right) = \prod^N_{i=1} \det\left(\frac{\partial g(g_i^{-1}(y|\theta))}{\partial x}\right).
\end{align}$$

Thus, we can use multiple bijective functions to compose a more complicated function. 

## Different flow architectures

### Coupling flows

[]({{ '/assets/images/coupling_flows.png' | relative_url}})

**In progress**

# References
- [Normalizing Flows: An Introduction and Review of Current Methods](https://arxiv.org/abs/1908.09257), Ivan *et al.* (2019)
- [Normalizing flows: Explicit distribution modeling](https://medium.com/@mechatronics420/normalizing-flows-introduction-ad1888771890), Ashish Jha, 12/10/2023 
- [What are normalising flows](https://www.youtube.com/watch?v=i7LjDvsLWCg&t=116s), Ari Seff, 7/12/2019
- [NICE: Non-linear Independent Components Estimation](https://arxiv.org/abs/1410.8516)

